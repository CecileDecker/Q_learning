{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First running of q-learning algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import numpy as np\n",
    "import copy \n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import binom\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the q-learning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q_learning import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_coins = 10\n",
    "X        = np.linspace(0, nr_coins, nr_coins+1)        # States\n",
    "A        = np.array([-1, 0, 1])                        # Actions\n",
    "\n",
    "def r(x,a,y):\n",
    "    return(a * (y>x) - a * (y<x) - np.abs(a) * (x==y)) # Reward function\n",
    "\n",
    "def P_0(x,a):\n",
    "    return binom.rvs(nr_coins, 0.5) # Assumption that is a fair coin\n",
    "\n",
    "alpha      = 0.95 # Discount Factor\n",
    "x_0        = 5    # Initial Value\n",
    "eps_greedy = 0.1  # Epsilon greedy policy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nr_iter = 100_000\n",
    "\n",
    "Q_opt_nonrobust = q_learning(X, A, r, P_0, alpha, x_0, eps_greedy, Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the functions that allow us to get the index of an element a (reps. x) in A (resp. X)\n",
    "if np.ndim(A) > 1:\n",
    "    A_list = A\n",
    "else:\n",
    "    A_list = np.array([[a] for a in A])\n",
    "if np.ndim(X) > 1:\n",
    "    X_list = X\n",
    "else:\n",
    "    X_list = np.array([[x] for x in X])\n",
    "\n",
    "def a_index(a):\n",
    "    return np.flatnonzero((a==A_list).all(1))[0]\n",
    "def x_index(x):\n",
    "    return np.flatnonzero((x==X_list).all(1))[0]\n",
    "\n",
    "# Get the result of the Q-Learning algorithm,\n",
    "# Get the optimal results for each x in X\n",
    "def a_opt_nonrobust(x):\n",
    "    return A[np.argmax(Q_opt_nonrobust[x_index(x), :])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[a_opt_nonrobust(x) for x in X]]))\n",
    "df[\"State\"]=[\"Non-Robust\"]\n",
    "df = df.set_index(\"State\").reset_index()\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each states we get the best \"bet\" we could make.\n",
    "This means that from each state we are we have an idea of what to do as an \"action\" to get the best result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observation of the sensitivities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nr_iter    = 100_000\n",
    "eps_greedy = 0.1\n",
    "\n",
    "Q_opt_nonrobust_alpha025 = q_learning(X, A, r, P_0, 0.25, x_0, eps_greedy, Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_alpha05  = q_learning(X, A, r, P_0, 0.5, x_0, eps_greedy, Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_alpha075 = q_learning(X, A, r, P_0, 0.75, x_0, eps_greedy, Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_alpha09  = q_learning(X, A, r, P_0, 0.9, x_0, eps_greedy, Nr_iter = Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_alpha095 = q_learning(X, A, r, P_0, 0.95, x_0, eps_greedy, Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_alpha099 = q_learning(X, A, r, P_0, 0.99, x_0, eps_greedy, Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_opt_nonrobust(x, Q_opt):\n",
    "    return A[np.argmax(Q_opt[x_index(x), :])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[a_opt_nonrobust(x, Q_opt_nonrobust_alpha025) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_alpha05) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_alpha075) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_alpha09) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_alpha095) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_alpha099) for x in X]]))\n",
    "df[\"State\"]=[\"Non-Robust, alpha = 0.25\",\"Non-Robust, alpha = 0.5\",\"Non-Robust, alpha = 0.75\",\"Non-Robust, alpha = 0.9\", \"Non-Robust, alpha = 0.95\", \"Non-Robust, alpha = 0.99\"]\n",
    "df = df.set_index(\"State\").reset_index()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nr_iter = 100_000\n",
    "alpha   = 0.95\n",
    "\n",
    "Q_opt_nonrobust_epsilon0    = q_learning(X, A, r, P_0, alpha, x_0, eps_greedy = 0, Nr_iter = Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_epsilon001  = q_learning(X, A, r, P_0, alpha, x_0, eps_greedy = 0.01, Nr_iter = Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_epsilon005  = q_learning(X, A, r, P_0, alpha, x_0, eps_greedy = 0.05, Nr_iter = Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_epsilon01   = q_learning(X, A, r, P_0, alpha, x_0, eps_greedy = 0.1, Nr_iter = Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))\n",
    "Q_opt_nonrobust_epsilon05   = q_learning(X, A, r, P_0, alpha, x_0, eps_greedy = 0.5, Nr_iter = Nr_iter, gamma_t_tilde = lambda t: 1/(t+1), Q_0 = np.ones([len(X),len(A)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[a_opt_nonrobust(x, Q_opt_nonrobust_epsilon0) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_epsilon001) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_epsilon005) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_epsilon01) for x in X],\n",
    "                            [a_opt_nonrobust(x, Q_opt_nonrobust_epsilon05) for x in X]]))\n",
    "df[\"State\"]=[\"Non-Robust, epsilon_greedy = 0\",\"Non-Robust, epsilon_greedy = 0.01\", \"Non-Robust, epsilon_greedy = 0.05\", \"Non-Robust, epsilon_greedy = 0.1\", \"Non-Robust, epsilon_greedy = 0.5\"]\n",
    "df = df.set_index(\"State\").reset_index()\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fa50da1a28b80a4de4afd4c3cc14474619d86344ca12217de50c84a2293bf6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
